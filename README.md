# ğŸ¡ California Housing - AnÃ¡lise de RegressÃ£o com Machine Learning

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![Streamlit](https://img.shields.io/badge/Streamlit-1.28+-red.svg)](https://streamlit.io/)
[![Scikit-learn](https://img.shields.io/badge/Scikit--learn-1.0+-orange.svg)](https://scikit-learn.org/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

## ğŸ“‹ DescriÃ§Ã£o do Projeto

Este projeto implementa uma aplicaÃ§Ã£o completa de **Machine Learning para RegressÃ£o** utilizando o dataset **California Housing** do scikit-learn. A aplicaÃ§Ã£o oferece uma interface interativa via Streamlit para anÃ¡lise exploratÃ³ria de dados (EDA), prÃ©-processamento e comparaÃ§Ã£o de mÃºltiplos algoritmos de regressÃ£o.

## ğŸ¯ Objetivos

- **AnÃ¡lise ExploratÃ³ria de Dados (EDA)** completa e visual
- **PrÃ©-processamento automÃ¡tico** de dados
- **ImplementaÃ§Ã£o profissional** de 10 algoritmos de regressÃ£o
- **OtimizaÃ§Ã£o de hiperparÃ¢metros** com GridSearch e RandomizedSearch
- **ComparaÃ§Ã£o sistemÃ¡tica** de performance entre modelos
- **Interface intuitiva** para usuÃ¡rios nÃ£o tÃ©cnicos

## ğŸš€ Funcionalidades

### ğŸ“Š AnÃ¡lise ExploratÃ³ria de Dados (EDA)
- EstatÃ­sticas descritivas completas
- AnÃ¡lise de correlaÃ§Ã£o entre variÃ¡veis
- VisualizaÃ§Ãµes interativas (histogramas, boxplots, scatter plots)
- DetecÃ§Ã£o automÃ¡tica de outliers e valores faltantes

### ğŸ¤– Algoritmos de RegressÃ£o Implementados

| Algoritmo | Status | OtimizaÃ§Ã£o | VisualizaÃ§Ãµes |
|-----------|--------|------------|---------------|
| **Random Forest** | âœ… Profissional | GridSearch + RandomizedSearch | Feature Importance, Hyperparameter Analysis |
| **XGBoost** | âœ… Implementado | GridSearch | Learning Curves, Feature Importance |
| **LightGBM** | âœ… Implementado | GridSearch | Learning Curves, Feature Importance |
| **CatBoost** | âœ… Implementado | GridSearch | Learning Curves, Feature Importance |
| **Gradient Boosting** | âœ… Implementado | GridSearch | Learning Curves, Feature Importance |
| **SVR (Support Vector Regression)** | âœ… Implementado | GridSearch | Kernel Analysis |
| **RegressÃ£o Linear** | âœ… Implementado | Ridge/Lasso/ElasticNet | Residual Analysis |
| **KNN** | âœ… Implementado | GridSearch | K-value Analysis |
| **HistGradientBoosting** | âœ… Implementado | GridSearch | Learning Curves |

### ğŸ”§ OtimizaÃ§Ã£o de HiperparÃ¢metros
- **GridSearchCV**: Busca exaustiva em grade de parÃ¢metros
- **RandomizedSearchCV**: Busca aleatÃ³ria eficiente
- **Cross-validation**: ValidaÃ§Ã£o cruzada com 5 folds
- **MÃ©tricas mÃºltiplas**: MAE, RMSE, RÂ²

## ğŸ› ï¸ Tecnologias Utilizadas

### Core ML
- **Scikit-learn**: Algoritmos de machine learning
- **NumPy**: ComputaÃ§Ã£o numÃ©rica
- **Pandas**: ManipulaÃ§Ã£o de dados
- **Matplotlib/Seaborn**: VisualizaÃ§Ãµes

### Interface e Deploy
- **Streamlit**: Interface web interativa
- **Plotly**: GrÃ¡ficos interativos avanÃ§ados

### OtimizaÃ§Ã£o
- **GridSearchCV**: OtimizaÃ§Ã£o de hiperparÃ¢metros
- **RandomizedSearchCV**: Busca eficiente de parÃ¢metros

## ğŸ“ Estrutura do Projeto

```
estudos/
â”œâ”€â”€ ğŸ“ modelos/                          # ImplementaÃ§Ãµes dos algoritmos
â”‚   â”œâ”€â”€ ğŸ†• modelo_random_forest.py      # Random Forest profissional
â”‚   â”œâ”€â”€ modelo_xgboost.py               # XGBoost
â”‚   â”œâ”€â”€ modelo_lightgbm.py             # LightGBM
â”‚   â”œâ”€â”€ modelo_catboost.py             # CatBoost
â”‚   â”œâ”€â”€ modelo_gradient_boosting.py    # Gradient Boosting
â”‚   â”œâ”€â”€ modelo_svr.py                  # Support Vector Regression
â”‚   â”œâ”€â”€ modelo_regressao_linear.py     # RegressÃ£o Linear
â”‚   â”œâ”€â”€ modelo_regressoes_lineares_reg.py # Ridge/Lasso/ElasticNet
â”‚   â”œâ”€â”€ modelo_knn.py                  # K-Nearest Neighbors
â”‚   â””â”€â”€ modelo_hist_gradient_boosting.py # Histogram-based GB
â”œâ”€â”€ ğŸ“„ main.py                          # AplicaÃ§Ã£o principal Streamlit
â”œâ”€â”€ ğŸ“„ eda.py                           # AnÃ¡lise exploratÃ³ria de dados
â”œâ”€â”€ ğŸ“„ datasets.py                      # Gerenciamento de datasets
â”œâ”€â”€ ğŸ“„ requirements.txt                 # DependÃªncias do projeto
â””â”€â”€ ğŸ“„ README.md                        # Este arquivo
```

## ğŸš€ Como Executar

### 1. PrÃ©-requisitos
```bash
Python 3.8+
pip ou conda
```

### 2. InstalaÃ§Ã£o
```bash
# Clone o repositÃ³rio
git clone https://github.com/seu-usuario/estudos.git
cd estudos

# Instale as dependÃªncias
pip install -r requirements.txt
```

### 3. ExecuÃ§Ã£o
```bash
# Execute a aplicaÃ§Ã£o Streamlit
streamlit run main.py
```

A aplicaÃ§Ã£o estarÃ¡ disponÃ­vel em: `http://localhost:8501`

## ğŸ“– Como Usar

### 1. **AnÃ¡lise ExploratÃ³ria (EDA)**
- Marque a checkbox "Exibir anÃ¡lise EDA" na sidebar
- Visualize estatÃ­sticas descritivas e correlaÃ§Ãµes
- Analise distribuiÃ§Ãµes e outliers

### 2. **SeleÃ§Ã£o de Modelo**
- Escolha um algoritmo na seÃ§Ã£o "Modelos"
- Cada modelo executa automaticamente:
  - Treinamento com dados de teste
  - OtimizaÃ§Ã£o de hiperparÃ¢metros
  - AvaliaÃ§Ã£o com mÃ©tricas mÃºltiplas
  - VisualizaÃ§Ãµes especÃ­ficas

### 3. **ComparaÃ§Ã£o de Modelos**
- Ative "Comparar todos os modelos" para anÃ¡lise comparativa
- Visualize mÃ©tricas lado a lado
- Identifique o melhor algoritmo para seu dataset

## ğŸ” Dataset: California Housing

O projeto utiliza o dataset **California Housing** que contÃ©m:

- **8 features**: MedInc, HouseAge, AveRooms, AveBedrms, Population, AveOccup, Latitude, Longitude
- **Target**: MedHouseVal (valor mediano das casas em blocos censitÃ¡rios da CalifÃ³rnia)
- **Tamanho**: 20,640 amostras
- **Tipo**: RegressÃ£o (valores contÃ­nuos)

## ğŸ—ï¸ Arquitetura do CÃ³digo

### Classe RandomForestModel (ImplementaÃ§Ã£o Profissional)
```python
class RandomForestModel:
    """
    ImplementaÃ§Ã£o profissional do Random Forest com:
    - Tratamento robusto de erros
    - Logging profissional
    - MÃ©todos modulares e reutilizÃ¡veis
    - DocumentaÃ§Ã£o completa
    """
    
    def train_baseline_model(self, X_train, y_train)
    def evaluate_model(self, model, X_test, y_test)
    def optimize_hyperparameters_grid(self, X_train, y_train)
    def optimize_hyperparameters_random(self, X_train, y_train)
    def plot_feature_importance(self)
    def plot_n_estimators_analysis(self)
    def plot_prediction_scatter(self)
```

### FunÃ§Ãµes Principais
- **`run_random_forest_analysis()`**: Nova funÃ§Ã£o principal profissional
- **`rodar_random_forest()`**: FunÃ§Ã£o legacy para compatibilidade

## ğŸ“Š MÃ©tricas de AvaliaÃ§Ã£o

### RegressÃ£o
- **MAE (Mean Absolute Error)**: Erro absoluto mÃ©dio
- **RMSE (Root Mean Square Error)**: Raiz do erro quadrÃ¡tico mÃ©dio
- **RÂ² (Coefficient of Determination)**: Coeficiente de determinaÃ§Ã£o

### InterpretaÃ§Ã£o
- **MAE/RMSE**: Quanto menor, melhor (0 = perfeito)
- **RÂ²**: Quanto mais prÃ³ximo de 1, melhor (1 = perfeito)

## ğŸ”§ ConfiguraÃ§Ãµes e PersonalizaÃ§Ã£o

### ParÃ¢metros ConfigurÃ¡veis
```python
# Random Forest
RANDOM_STATE = 42
DEFAULT_N_ESTIMATORS = 100
CV_FOLDS = 5
RANDOM_SEARCH_ITERATIONS = 20

# HiperparÃ¢metros de busca
GRID_SEARCH_PARAMS = {
    'n_estimators': [50, 100, 200],
    'max_depth': [None, 10, 20],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4]
}
```

## ğŸš€ PrÃ³ximos Passos

### Melhorias Planejadas
- [ ] ImplementaÃ§Ã£o profissional para todos os algoritmos
- [ ] AdiÃ§Ã£o de mais datasets de exemplo
- [ ] Sistema de experimentos com MLflow
- [ ] API REST com FastAPI
- [ ] Deploy automatizado com CI/CD
- [ ] Testes unitÃ¡rios e de integraÃ§Ã£o
- [ ] DocumentaÃ§Ã£o automÃ¡tica com Sphinx

### Novos Algoritmos
- [ ] Deep Learning com TensorFlow/PyTorch
- [ ] Ensemble methods avanÃ§ados
- [ ] AutoML com Auto-sklearn
- [ ] Interpretabilidade com SHAP/LIME

## ğŸ¤ ContribuiÃ§Ã£o

ContribuiÃ§Ãµes sÃ£o bem-vindas! Para contribuir:

1. **Fork** o projeto
2. **Crie** uma branch para sua feature (`git checkout -b feature/AmazingFeature`)
3. **Commit** suas mudanÃ§as (`git commit -m 'Add some AmazingFeature'`)
4. **Push** para a branch (`git push origin feature/AmazingFeature`)
5. **Abra** um Pull Request

### PadrÃµes de CÃ³digo
- Siga **PEP 8** para estilo Python
- Use **type hints** em todas as funÃ§Ãµes
- Documente com **docstrings** completas
- Implemente **tratamento de erros** robusto
- Adicione **logging** apropriado

## ğŸ“š Recursos de Aprendizado

### Machine Learning
- [Scikit-learn Documentation](https://scikit-learn.org/stable/)
- [Machine Learning Mastery](https://machinelearningmastery.com/)
- [Towards Data Science](https://towardsdatascience.com/)

### Streamlit
- [Streamlit Documentation](https://docs.streamlit.io/)
- [Streamlit Gallery](https://streamlit.io/gallery)

### Boas PrÃ¡ticas
- [Google Python Style Guide](https://google.github.io/styleguide/pyguide.html)
- [Real Python](https://realpython.com/)

## ğŸ“„ LicenÃ§a

Este projeto estÃ¡ licenciado sob a LicenÃ§a MIT - veja o arquivo [LICENSE](LICENSE) para detalhes.

## ğŸ‘¨â€ğŸ’» Autor

**JoÃ£o Silva** - [GitHub](https://github.com/seu-usuario)

## ğŸ™ Agradecimentos

- Dataset: [California Housing](https://scikit-learn.org/stable/datasets/real_world.html#california-housing-dataset)
- Comunidade scikit-learn
- Streamlit team
- Contribuidores open source

---

â­ **Se este projeto foi Ãºtil, considere dar uma estrela!**

ğŸ“§ **Contato**: [seu-email@exemplo.com](mailto:seu-email@exemplo.com)

ğŸ”— **LinkedIn**: [Seu Perfil](https://linkedin.com/in/seu-perfil)
